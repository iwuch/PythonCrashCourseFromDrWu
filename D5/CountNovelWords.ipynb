{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#利用集合对读取文中出现单词列表进行去重，并且统计出现的“单词”的词数\n",
    "with open(\"./books/alice.txt\",\"r\") as file:\n",
    "    contents = file.read()\n",
    "wordslist = contents.split()\n",
    "wordset = set(wordslist)\n",
    "count = len(wordset)\n",
    "print(count)\n",
    "print(wordset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去掉非单词符号之后，统计真正的单词的次数\n",
    "with open(\"./books/alice.txt\",\"r\") as file:\n",
    "    contents = file.read()\n",
    "puncs = [\"'\",'.',',','?','-','!','\\\"',':',';','(',')',']','[','_']\n",
    "for punc in puncs:\n",
    "    contents = contents.replace(punc,\" \")\n",
    "wordslist = contents.split()\n",
    "wordset = set(wordslist)\n",
    "count = len(wordset)\n",
    "print(count)\n",
    "print(wordset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立单词字数的词典，对每个单词出现的次数进行统计之后存入到字典中\n",
    "#去掉非单词符号之后，统计真正的单词的次数\n",
    "with open(\"./books/alice.txt\",\"r\") as file:\n",
    "    contents = file.read()\n",
    "puncs = [\"'\",'.',',','?','-','!','\\\"',':',';','(',')',']','[','_']\n",
    "for punc in puncs:\n",
    "    contents = contents.replace(punc,\" \")\n",
    "wordslist = contents.split()\n",
    "wordset = set(wordslist)\n",
    "wordic = {}\n",
    "for word in wordset:\n",
    "    wordic[word] = wordslist.count(word)\n",
    "for word in wordic:\n",
    "    print(f\"{word}:{wordic[word]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对wordic中的单词按照单词出现的词频进行排序\n",
    "for word in sorted(wordic,key = wordic.__getitem__,reverse = True):\n",
    "    print(f\"{word}:{wordic[word]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#过滤掉长度特别短的词和停用词\n",
    "#停用词可以根据自己的需求自定义\n",
    "stopwords = ['little','again','herself','could','would','There',\n",
    "              'thought','The','And','You','What','She','But','March','according','united','states']\n",
    "for word in sorted(wordic,key = wordic.__getitem__,reverse = True):\n",
    "    if len(word) > 3 and word not in stopwords:\n",
    "        print(f\"{word}:{wordic[word]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通过istitle()来判定是否首字母大写\n",
    "for word in sorted(wordic,key = wordic.__getitem__,reverse = True):\n",
    "    if len(word) > 3 and word not in stopwords and word[0].istitle():\n",
    "        print(f\"{word}:{wordic[word]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#如果没有安装依赖，使用pip install指令安装\n",
    "# !pip install pyecharts_jupyter_installer  \n",
    "# !pip install pyecharts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建绘制词云图所需要的参数列表\n",
    "words = []\n",
    "for word in sorted(wordic,key = wordic.__getitem__,reverse = True):\n",
    "    if len(word) > 3 and word not in stopwords and word[0].istitle():\n",
    "        words.append((word,wordic[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用pyecharts生成词云图，可视化展示专有名词（首字母大写词）词频\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Page, WordCloud\n",
    "from pyecharts.globals import SymbolType\n",
    "def wordcloud_base() -> WordCloud:\n",
    "    c = (\n",
    "        WordCloud()\n",
    "        .add(\"\", words, word_size_range=[20, 100])\n",
    "        .set_global_opts(\n",
    "            title_opts=opts.TitleOpts(\n",
    "                title=\"THE CHARACTER NAMES OF THE HIGHEST FREQUENCY\"))\n",
    "    )\n",
    "    return c\n",
    "\n",
    "wd = wordcloud_base()\n",
    "wd.render(\"./highFrequencyCharacters.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#我们如果需要提取长度前10的名字，只需要在构建words列表的时候进行判断即可\n",
    "words = []\n",
    "for word in sorted(wordic,key = wordic.__getitem__,reverse = True):\n",
    "    if len(word) > 3 and word not in stopwords and word[0].istitle():\n",
    "        words.append((word,wordic[word]))\n",
    "    if len(words) >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/nas/workspace/jupyter/tutorials/Lesson5/Top10HighFrequencyCharacters.html'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用pyecharts生成词云图，可视化展示专有名词（首字母大写词）词频\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Page, WordCloud\n",
    "from pyecharts.globals import SymbolType\n",
    "def wordcloud_base() -> WordCloud:\n",
    "    c = (\n",
    "        WordCloud()\n",
    "        .add(\"\", words, word_size_range=[20, 100])\n",
    "        .set_global_opts(\n",
    "            title_opts=opts.TitleOpts(\n",
    "                title=\"THE CHARACTER NAMES OF THE TOP 10 HIGHEST FREQUENCY\"))\n",
    "    )\n",
    "    return c\n",
    "\n",
    "wd = wordcloud_base()\n",
    "wd.render(\"./Top10HighFrequencyCharacters.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通过csv模块来保存高频词和频率信息\n",
    "import csv\n",
    "headers = ['word','count']\n",
    "with open('word_count.csv','w',newline='') as f:\n",
    "    #新建一个用来写文件的对象csv.writer\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
